# Agent C の批判的レビュー

> 制御フロー・可観測性アーキテクト（Agent C）として、Agent A（耐障害性）と Agent B（シンプリシティ）の提案を批判的にレビューする。

---

## Agent A（耐障害性）への評価

### 同意する点

**1. in_progress タスクの優先再開（提案1）は的確かつ最小限の変更で最大効果を得る**

Agent A が指摘する「in_progress タスクが再起動時に放棄される」問題（問題点8）は、私の分析でも見落としていた重要な障害パターンである。base.md の Step 3 に `--status in_progress` の確認を3行追加するだけで、クラッシュリカバリの最も基本的なケースをカバーできる。テンプレートの複雑化も最小限であり、LLM の遵守率を低下させるリスクも低い。**即時採用すべき提案**である。

**2. plan.md の安全な書き込みパターン（提案2）は本質的に正しい**

heredoc による plan.md の上書きが非原子的である問題は、私の提案3（Phase 状態マシン）とも関連する。backup → tmp 書き込み → バリデーション → mv という手順は、ファイル操作の基本的な安全パターンであり、反論の余地がない。ただし後述の通り、この提案には重大な盲点がある。

**3. setup_mission の冪等性確保（提案3）はインフラレベルの正しい改善**

Python コードの修正であり LLM の不確実性に影響されない点は、Agent B の「ロジックをプログラムコードに移す」思想と一致する。ミッション起動の信頼性はシステム全体の前提条件であり、ここが壊れると全てが破綻する。**優先度 High に同意する**。

**4. 設計哲学への提言は本質を突いている**

> 「LLM の出力を信頼せず、検証する」「最悪のケースでも人間に通知が届く設計にする」

この2つの原則は、私の可観測性仮説とも完全に整合する。特に後者は三者の提案を統合する際の最上位原則として採用すべきである。

### 反論する点

**1. 提案2（plan.md 安全書き込み）は「壊れたことに気づけない」問題を解決しない**

Agent A の提案2は「plan.md が壊れないようにする」防御策だが、**壊れた場合にどう検知するか**の仕組みがない。具体的に:

- `diff` コマンドで構造変更を検出する案があるが、これは brain のセッション内でのみ実行される。brain が diff を見て「WARNING」を echo したところで、**そのメッセージは誰が見るのか？** セッションログに埋もれるだけである。
- backup ファイル（`.bak.YYYYMMDDHHMMSS`）は蓄積されるが、**誰がこれを比較するのか？** 自動的に差分を検知して人間に通知する仕組みがなければ、backup は事後のフォレンジック用にしかならない。
- つまり「壊れにくくする」ことと「壊れたことに気づく」ことは別の問題であり、Agent A は前者のみを扱っている。

**私の提案4（Plan Drift 検知）と組み合わせなければ、この安全策は「目隠しをした上で頑丈な鎧を着る」ようなものだ。** 鎧が破れた時に初めて問題が顕在化するが、その時にはもう手遅れである。

**2. brain-monitor 相互監視（提案4）は可観測性なき耐障害であり「盲目的回復」のリスクがある**

Agent A の提案4は、brain と monitor が互いの cron 状態を監視し、死んだ方を復旧するという相互監視パターンである。耐障害性の観点からは正しいが、**可観測性の観点からは重大な欠陥がある**:

- **復旧の判断根拠が記録されない**: monitor が brain の cron を再有効化した場合、なぜ brain が死んでいたのか、brain が最後に何をしていたのかの情報なしに盲目的に再起動する。brain が「plan.md を壊した直後にクラッシュした」場合、再起動した brain は壊れた plan.md を読んで更に状態を悪化させる可能性がある。
- **復旧イベントが人間に通知されない**: cron 再有効化は静かに行われ、人間は brain がクラッシュして復旧したことを知らない。これは Agent A 自身が指摘する「サイレント障害」そのものである。
- **復旧の成否が確認されない**: cron を再有効化しても、次のトリガーで brain が正常に起動する保証はない。同じ原因で再度クラッシュする可能性がある。復旧試行の回数制限やバックオフ機構がない。

**相互監視は「復旧ログの記録」「人間への通知」「復旧成否の追跡」とセットでなければ危険である。** 私の提案1（Decision Log）に復旧イベントを記録し、escalator 経由で人間に通知するフローを組み合わせるべきだ。

**3. LLM ガードレール（提案5）のテンプレートレベル制限は実効性に疑問がある**

> 「Task creation limit: Create at most 7 tasks per session」
> 「Escalation threshold: If you are uncertain about any decision (confidence < 70%), escalate」

これらは自然言語の指示であり、Agent A 自身が問題点4で指摘した「LLM の指示無視」に対する解決策としては循環論法になっている。「指示を無視する問題」に対して「指示を追加する」ことで解決しようとしている。

監査ログ（audit.jsonl）の案は正しい方向だが、mc CLI の改修が必要と述べながら具体的な実装に踏み込んでいない。**「LLM に指示する」のではなく「mc CLI 側で制限を強制する」べきである。** 例えば `mc add` にセッション単位のレート制限を実装するなど。

**4. エスカレーション到達保証（提案6）の優先度 Low 判定は楽観的すぎる**

Agent A は提案6を Low としているが、この判断は「escalator の cron が6時間以内に正常実行される確率は十分高い」という楽観的な仮定に基づいている。しかし:

- Agent A 自身が問題点1で指摘したように、Cron Guard 失敗で escalator がスタックする可能性がある
- Agent A 自身が問題点7で「クリティカルなエスカレーションが最大6時間遅延しうる」と述べている
- **「壊れた時に人間に通知が届く」ことはシステム全体の安全弁であり、Low であるはずがない**

人間への通知は「最後の砦」であり、ここが壊れるとシステム全体の信頼性モデルが崩壊する。私の提案5c（brain の指示解釈確認 → escalator 経由で人間に報告）も同様の思想に基づいている。

### 見逃している点

**1. 「障害が発生したという事実」自体の可視化が欠落している**

Agent A の提案は「障害を防ぐ」「障害から回復する」に焦点を当てているが、**「障害が発生した回数、頻度、パターンを人間が把握できるか」** という視点が欠落している。

- Cron Guard が何回失敗したか？
- in_progress タスクの再開が何回発生したか？
- plan.md のバリデーション失敗が何回あったか？

これらの統計情報がなければ、人間はシステムの健全性を判断できない。「たまに壊れるが自動回復している」のか「頻繁に壊れており根本原因の対処が必要」なのかが分からない。

**2. 耐障害メカニズム自体の失敗モードが分析されていない**

Agent A は各提案のトレードオフを述べているが、**耐障害メカニズム自体が失敗した場合のフォールバック**が体系的に分析されていない。例えば:

- ファイルロック（提案7）の `.lock` ファイルが壊れた場合 → 30分タイムアウトで緩和と述べているが、その30分間にどうなるか？
- セッション状態ファイル（提案8）の JSON が壊れた場合 → 無限ループに陥る可能性は？
- 相互監視（提案4）で brain と monitor が互いに相手を復旧し続けるカスケード障害は？

**耐障害メカニズムを追加するほど、そのメカニズム自体が新たな障害点になる。** この再帰的な問題に対する回答が必要である。

**3. 人間が「今すぐ」システムの状態を確認する手段が提案されていない**

Agent A の提案はすべて「エージェントが自動的に対処する」仕組みであり、人間が能動的にシステムの状態を調査するためのツールが提案されていない。私の提案5b（dashboard コマンド）に相当するものがない。

---

## Agent B（シンプリシティ）への評価

### 同意する点

**1. Cron Guard の CLI 化（提案1）は三者共通の最優先改善項目である**

Agent B の定量分析「13箇所 x 失敗確率 5% = セッションあたり約 49% の確率で少なくとも1回の Cron Guard 失敗」は説得力がある（確率の見積もりには議論の余地があるが、方向性は正しい）。`mc cron-guard disable {agent_id}` の1コマンド化は:

- LLM の生成ミスリスクを根本的に排除する
- テンプレートの行数を削減し、認知負荷を下げる
- 実装コストが低い（mc CLI に50行程度）
- Agent A の問題点1（Cron Guard のベストエフォート方式）も緩和する

**三者の提案の中で、最もコスト対効果が高い改善である。**

**2. Phase 管理の CLI 化（提案3）は長期的に正しい方向性**

brain が plan.md を heredoc で直接書き換える現行設計は、Agent A（plan.md 破損リスク）、Agent C（Phase 遷移の可視化不足）、Agent B（LLM の認知負荷）のすべてが問題視している。`mc phase status` / `mc phase propose` / `mc phase create-tasks` のコマンド化は:

- plan.md 破損リスクを排除（Agent A の問題点3を解決）
- Phase 遷移をプログラム的に管理可能にする（Agent C の提案3の発展形）
- brain.md を60行から15行に削減（Agent B の問題点3を解決）

**ただし、優先度 Low という判定には反対する。** 後述の通り、Phase 管理こそが可観測性の基盤であり、中期的に必ず必要になる。

**3. cron メッセージの最小化（提案6）は即座に実施すべき**

Single Source of Truth を AGENTS.md に一本化する考えは正しい。cron メッセージとテンプレートの齟齬は Agent A の問題点4（Instruction Drift）の直接的な原因の一つである。実装コストがほぼゼロであることも大きい。

**4. 「信頼性は仕組みの単純さで担保すべき」という結論には全面的に賛同する**

> 複雑なロジックは **プログラムコード** (mc CLI) に移す → 決定論的に動作
> LLM には **単純な判断** と **単純なコマンド呼び出し** のみを任せる

この設計原則は、Agent A のガードレール提案（自然言語で制限を指示する）よりも本質的に優れている。LLM の不確実性を「指示の追加」で対処しようとするのは限界がある。不確実性を「仕組みで封じ込める」Agent B のアプローチが正しい。

### 反論する点

**1. Supervisor 統合（提案2）は可観測性を大幅に犠牲にする — これが最大の論争点**

Agent B は monitor + brain + escalator を brain 単一に統合することを提案している。API コスト67%削減、レイテンシ削減は魅力的だが、**可観測性の観点から重大なリスクがある**:

**(a) 「観察者」と「行為者」の同一化は客観性を失う**

現行の monitor は brain とは独立した視点でシステムを観察する。brain が暴走して plan にないタスクを大量作成しても、monitor は独立した観察者として異常を検知できる可能性がある。brain に monitor を統合すると、**brain が自分自身の異常を検知する**ことを期待することになる。これは「泥棒に自分の犯罪を報告させる」ようなものだ。

具体例: brain が Phase 管理ロジックを誤って Phase 2 のタスクを Phase 1 完了前に作成した場合:
- 現行: monitor が board を観察し、plan との乖離を（Plan Drift 検知があれば）検出可能
- 統合後: brain が自分で board を観察するが、自分の判断が正しいと「信じている」ため、乖離に気づけない

**(b) brain セッションが長くなると、失敗した場合の影響範囲が拡大する**

統合 brain は「観察 → 判断 → タスク作成 → エスカレーション」の全てを1セッションで行う。セッション途中でクラッシュした場合:
- 観察は完了したがタスク作成前にクラッシュ → 次回起動で再度やり直し（軽微）
- タスクを3つ作成した後にクラッシュ → 残り2つのタスクが欠落、cron 再有効化もされない → 部分的な Phase 進行
- エスカレーション処理中にクラッシュ → 人間への通知が失われる

分割されていれば、各 Supervisor は独立したセッションとして短時間で完了し、1つが失敗しても他は影響を受けない。

**(c) コスト削減の計算には「リスクコスト」が含まれていない**

Agent B は「API コスト67%削減」と述べるが、統合による障害リスクの増加コスト（復旧の人的コスト、ミッション遅延のコスト）を計算に入れていない。3つの独立した Supervisor が6時間ごとに起動するコスト vs. 1つの統合 brain が障害で全機能を喪失するリスクコストの比較が必要。

**ただし、Agent B の指摘する「monitor → brain の伝言ゲーム（最大12時間のレイテンシ）」は正当な問題であり、これに対する代替案は後述の統合提案で扱う。**

**2. 「関心の分離」を軽視する論拠が不十分**

Agent B は:
> LLM エージェントの文脈では「関心の分離」よりも「実行の確実性」が優先されるべき

と述べるが、この論理は「LLM は1つのセッションで全てを処理した方が情報のロスがない」という仮定に基づいている。しかし:

- LLM のセッションが長くなるほど、後半の指示の遵守率が低下する（Agent A の問題点4とも一致）
- 統合 brain のテンプレートは、現行の brain.md（215行）+ monitor.md（99行）+ escalator.md（99行）の機能を統合するため、**更に長くなる可能性がある**
- Agent B の提案3（Phase 管理 CLI 化）で brain.md を短縮する前提だが、提案3は Low 優先度と位置づけられている。提案2と提案3の実施順序に矛盾がある。

**統合するなら、先に Phase 管理 CLI 化（提案3）で brain の複雑度を下げてからでなければ、統合後の brain テンプレートが肥大化して逆効果になる。**

**3. 障害点の定量分析（問題5）は「見える障害」のみで「見えない障害」を扱っていない**

Agent B は15箇所の障害点を列挙し、提案1と提案2で「15 → 8」に削減できると述べている。この分析は有用だが、**列挙されている障害点は全て「技術的な障害」であり、「認知的な障害」が含まれていない**:

- brain が plan.md の意図を誤解釈する（私の問題点6）
- brain が Phase の完了基準を誤判定する（私の問題点3の一部）
- 人間が現在の状態を把握できない（私の問題点2, 4）

これらは LLM の判断品質に関わる障害であり、システムの単純化だけでは解決しない。**「仕組みの単純さ」は必要条件だが十分条件ではない。**

### 見逃している点

**1. 人間の信頼（trust）構築の視点が完全に欠落している**

Agent B の提案はすべて「システムの内部効率」に焦点を当てており、**人間がシステムを信頼できるか**という視点がない。

- dashboard やログ閲覧の手段が提案されていない
- 人間が能動的にミッションに介入するフローが考慮されていない
- 人間が「何が起きているか分からない」ときにどうするかの回答がない

Agent B の統合提案が実現すると、Supervisor が brain 1つだけになる。人間の視点からは「ブラックボックスの brain が全てを決めている」状態になり、信頼が構築できない。**人間の信頼なくしてシステムの運用は成り立たない。**

**2. Supervisor 統合後の「brain が暴走した場合の安全弁」が設計されていない**

現行設計で brain が暴走した場合:
- monitor が異常を検知する可能性がある（独立した観察者として）
- escalator が人間に通知する（brain が作成した escalation タスクを処理）

統合後に brain が暴走した場合:
- brain 自身が自分の暴走を検知する？ → 期待できない
- brain がセッション出力として異常を報告する？ → 暴走している brain は正しい出力を生成しない
- 人間が `mc board` で気づく？ → 能動的に確認しなければ気づけない

**統合するなら、brain の外部に「watchdog」的な仕組みが必要。** それが結局 monitor と同じ役割になるのであれば、統合の意味が薄れる。

**3. エスカレーション機能の統合リスクが過小評価されている**

Agent B は「escalator の存在意義が薄い」と述べ、cron の `--announce` で代替できるとしている。しかし:

- brain が正常にセッションを完了しなければ `--announce` は発火しない
- brain がクラッシュした場合、そのセッションで検知した全てのエスカレーション情報が失われる
- 現行設計では escalator が独立して動作するため、brain がクラッシュしても escalator は自身のタスクキューを処理できる

**escalator の独立性は「brain が壊れても人間に通知が届く」という安全弁であり、コスト削減のために犠牲にすべきではない。**

---

## 三者統合への提案

三者の視点を統合し、各提案の強みを活かしつつ弱みを補完する設計方針を提案する。

### 設計原則

1. **Agent B の原則を基盤にする**: 複雑なロジックはプログラムコード（mc CLI）に移し、LLM には単純な判断とコマンド呼び出しのみを任せる
2. **Agent A の耐障害パターンを組み込む**: ただし、耐障害メカニズムには必ず可観測性を伴わせる
3. **Agent C の可観測性を横断的に適用する**: 全ての操作に対して「何が起きたか」「なぜそうなったか」を追跡可能にする

### 統合アーキテクチャ

#### Phase 1（即時実施 — テンプレート変更 + 最小限の CLI 追加）

| 項目 | 出典 | 実装内容 |
|------|------|----------|
| **Cron Guard CLI 化** | Agent B 提案1 | `mc cron-guard disable/enable` コマンド追加。全テンプレートを1行化 |
| **in_progress タスクの優先再開** | Agent A 提案1 | base.md の Step 3 に `--status in_progress` 確認を追加 |
| **cron メッセージの最小化** | Agent B 提案6 | setup_mission.py の cron メッセージを `"Read your AGENTS.md and execute your workflow."` に |
| **plan.md の安全書き込み** | Agent A 提案2 | brain.md に backup → tmp → validate → mv パターンを追加 |
| **brain の指示解釈確認** | Agent C 提案5c | brain.md の User Instructions 処理にログ記録 + escalator 報告を追加 |
| **タスク作成自己検証** | Agent C 提案6 | brain.md のタスク作成後に `mc list` で検証ステップを追加 |

#### Phase 2（短期 — mc CLI への機能追加）

| 項目 | 出典 | 実装内容 |
|------|------|----------|
| **YAML フロントマター** | Agent C 提案2 | plan.md に構造化フロントマター導入。brain はフロントマター優先参照 |
| **setup_mission の冪等性** | Agent A 提案3 | register_agent に存在確認を追加。リトライ安全化 |
| **Decision Log** | Agent C 提案1 | decision-log.jsonl に brain/monitor の判断を記録。`mc log` コマンド追加 |
| **Plan Drift 検知** | Agent C 提案4 | monitor にフロントマターとの乖離検知を追加 |

#### Phase 3（中期 — アーキテクチャレベルの改善）

| 項目 | 出典 | 実装内容 |
|------|------|----------|
| **Phase 管理 CLI 化** | Agent B 提案3 + Agent C 提案3 | `mc phase status/propose/create-tasks` コマンド。Phase 遷移をプログラム的に管理 |
| **Supervisor の部分統合** | 統合案 | monitor を brain に統合（escalator は独立維持）。詳細は下記 |
| **dashboard コマンド** | Agent C 提案5b | `mc dashboard` で Phase 進捗 + タスク状態 + エージェント状態 + 直近ログを一覧表示 |

### Supervisor 部分統合の詳細

Agent B の Supervisor 完全統合と、現行の3分割の中間案を提案する:

```
現行:    monitor(観察) + brain(判断) + escalator(通知) = 3エージェント
Agent B: brain(観察+判断+通知) = 1エージェント
統合案:  brain(観察+判断) + escalator(通知) = 2エージェント
```

**理由**:

1. **monitor → brain の統合は合理的**: Agent B が指摘する通り、monitor の観察結果を brain が次回サイクルで読むレイテンシ（最大12時間）は無意味に長い。brain が自分で `mc board` と `mc fleet` を読めばよい。brain.md の Step 3 で既に board を確認しているため、monitor の機能を統合しても認知負荷の増加は限定的。
2. **escalator は独立させるべき**: escalator は「brain が壊れても人間に通知が届く」安全弁として機能する。brain がクラッシュしても、既に作成された escalation タスクを escalator が独立して処理できる。
3. **コスト**: 3エージェント → 2エージェントで API コスト33%削減。完全統合の67%には劣るが、安全弁を維持できる。

**統合 brain のテンプレートに追加する monitor 由来の機能**:

```markdown
### 2. Observe (Board & Fleet Status)
mc -p {project} -m {mission} board
mc -p {project} fleet

Check for:
- Blocked tasks: escalate or reassign
- Stale tasks (no progress > 24h): reassign or break down
- Stale agents (last_seen > 20min + has tasks): mc cron-guard enable <agent-id>
- All tasks done: proceed to Phase management

Log observation to decision-log.jsonl.
```

**brain と escalator の相互 cron 監視（Agent A 提案4の適用）**:
- brain は escalator の cron 状態を確認し、無効なら再有効化
- escalator は brain の cron 状態を確認し、無効なら再有効化 + 人間に `[BRAIN_DOWN]` 通知
- 復旧イベントは必ず decision-log.jsonl に記録する

### 人間の信頼構築フレームワーク

三者の提案を統合する際、**全ての設計判断を「人間の信頼」というレンズで再評価する**:

| 信頼の構成要素 | 対応する仕組み | 提供するエージェント |
|---------------|---------------|-------------------|
| **透明性** (何が起きているか分かる) | dashboard コマンド、decision-log、mc board/fleet | Agent C |
| **予測可能性** (次に何が起きるか分かる) | Phase 状態表示、YAML フロントマターの計画情報 | Agent C |
| **制御可能性** (人間が介入できる) | mission instruct --run-brain、checkpoint、pause/resume | Agent C |
| **堅牢性** (壊れにくい) | Cron Guard CLI 化、安全書き込み、冪等性 | Agent A + B |
| **回復可能性** (壊れても直る) | in_progress 再開、相互 cron 監視、Plan Drift 検知 | Agent A |
| **説明可能性** (なぜそうなったか分かる) | Decision Log、design_intent フィールド | Agent C |

---

## 絶対に譲れない点

可観測性アーキテクトとして、**いかなる最終設計であっても以下の要件は必須**とする。これらが欠けたシステムは「動くが信頼できない」ものになる。

### 1. 全ての判断には記録が伴わなければならない

brain がタスクを作成する、Phase を進める、タスクを再割当する — これらの判断の根拠を構造化して記録する仕組みがなければ、ミッション失敗時の原因分析が不可能になる。Decision Log（提案1）は形式は問わないが、機能として必ず実装すべきである。

**これは Agent A の耐障害メカニズムにも適用される。** 相互監視で cron を再有効化した、ファイルロックでセッションを中止した、in_progress タスクを再開した — これらの全てのイベントが記録されなければ、耐障害メカニズムが正しく機能しているかの検証ができない。

### 2. 人間がリアルタイムでシステム状態を確認できる手段がなければならない

`mc board` と `mc fleet` は存在するが、Phase レベルの進捗、直近の brain の判断、異常検知の履歴を統合的に表示する手段がない。最低限 `mc log` コマンドによるログ閲覧、理想的には `mc dashboard` による統合ビューが必要である。

### 3. plan.md（あるいはその後継）の解釈には構造的保証がなければならない

architect が設計した意図が brain に正確に伝わる保証がない現状は、OMOS の信頼性の根本的なボトルネックである。YAML フロントマター（提案2）か Phase 管理 CLI 化（Agent B 提案3）か、手段は問わないが、**自然言語パースへの完全依存からの脱却は必須**である。

### 4. 人間への通知経路は brain から独立していなければならない

brain が唯一の Supervisor であり、かつ brain がクラッシュした場合、人間には何の通知も届かない。これは許容できない。escalator の独立性、あるいはそれに代わる brain 外部からの通知メカニズムは必ず維持すべきである。

Agent B のコスト最適化提案は理解するが、**「brain が壊れたことを人間が知る手段」を全て brain に依存させてはならない。** これは可観測性における最も基本的な原則 — **観測者は観測対象から独立していなければならない** — に反する。

### 5. 異常検知は「想定された障害パターン」だけでなく「想定外の逸脱」も検出すべき

Agent A の耐障害提案は「既知の障害パターン」（クラッシュ、cron 無効化、plan.md 破損）に対処するが、「未知の障害パターン」（brain が plan にないタスクを作成、Priority の逸脱、Phase 順序の違反）への対処が弱い。Plan Drift 検知（提案4）はこの「想定外の逸脱」を検出するために不可欠であり、monitor を brain に統合した場合でも、何らかの形で drift 検知の仕組みは維持しなければならない。
